# -*- coding: utf-8 -*-
"""
Created on Thu Nov  6 16:56:08 2025

@author: loren
"""

import numpy as np
import itertools
from typing import List
import pandas as pd
from pathlib import Path
from datetime import datetime

CSV_DIR  = Path(r"C:\Users\loren\Desktop\Tesi_magi\codes\kriging_out")  # ← cambia qui
STATION_CSV_FILE = "station_precipitation_table.csv"
PIXEL_CSV_FILE = "pixel_precipitazion_table.csv"                          # ← o cambia nome
OUTPUT_DIR = Path(r"C:\Users\loren\Desktop\Tesi_magi\codes\model_out")

def _safe_mean(values: np.ndarray) -> float:
    if values.size == 0:
        return float("nan")
    return float(np.mean(values))


def _compute_parameters(h_1: np.ndarray, h_2: np.ndarray) -> dict:
    if h_1.shape != h_2.shape:
        raise ValueError("Rainfall series must have the same length")

    valid_mask = (~np.isnan(h_1)) & (~np.isnan(h_2))
    h_1 = h_1[valid_mask]
    h_2 = h_2[valid_mask]

    if h_1.size == 0:
        raise ValueError("No overlapping data between the two rainfall series")

    length_series = h_1.size

    lambda_1t = np.sum(h_1 > 0) / length_series
    lambda_2t = np.sum(h_2 > 0) / length_series

    lambda_1 = np.sum((h_1 > 0) & (h_2 == 0)) / length_series
    lambda_2 = np.sum((h_2 > 0) & (h_1 == 0)) / length_series
    lambda_12 = np.sum((h_1 > 0) & (h_2 > 0)) / length_series

    alpha_1t = _safe_mean(h_1[h_1 > 0])
    alpha_2t = _safe_mean(h_2[h_2 > 0])

    alpha_1 = _safe_mean(h_1[(h_1 > 0) & (h_2 == 0)])
    alpha_2 = _safe_mean(h_2[(h_2 > 0) & (h_1 == 0)])

    alpha_1_12 = _safe_mean(h_1[(h_1 > 0) & (h_2 > 0)])
    alpha_2_12 = _safe_mean(h_2[(h_1 > 0) & (h_2 > 0)])

    synchronous_h_1 = h_1[(h_1 > 0) & (h_2 > 0)]
    synchronous_h_2 = h_2[(h_1 > 0) & (h_2 > 0)]

    if synchronous_h_1.size > 1:
        r_alpha_12 = float(np.corrcoef(synchronous_h_1, synchronous_h_2)[0, 1])
    else:
        r_alpha_12 = float("nan")

    if lambda_1t > 0 and lambda_2t > 0 and not np.isnan(r_alpha_12):
        rho_1 = lambda_12 / np.sqrt(lambda_1t * lambda_2t) * 0.5 * (1 + r_alpha_12)
        rho_2 = lambda_12 * alpha_1_12 * alpha_2_12 /np.sqrt((lambda_1 * (alpha_1)**2 + lambda_12 * (alpha_1_12)**2) * (lambda_2 * (alpha_2)**2 + lambda_12 * (alpha_1_12)**2)) * 0.5 * (1 + r_alpha_12)
        rho_3 = lambda_12 / np.sqrt(lambda_1t * lambda_2t) * 0.5 * (1 + r_alpha_12) * alpha_1_12 * alpha_2_12 / (alpha_1t * alpha_2t)
    else:
        rho_1 = float("nan")
        rho_2 = float("nan")
        rho_3 = float("nan")

    return {
        "lambda_1t": lambda_1t,
        "lambda_2t": lambda_2t,
        "lambda_1": lambda_1,
        "lambda_2": lambda_2,
        "lambda_12": lambda_12,
        "alpha_1t": alpha_1t,
        "alpha_2t": alpha_2t,
        "alpha_1": alpha_1,
        "alpha_2": alpha_2,
        "alpha_1_12": alpha_1_12,
        "alpha_2_12": alpha_2_12,
        "r_alpha_12": r_alpha_12,
        "rho_1": rho_1,
        "rho_2": rho_2,
        "rho_3": rho_3
    }


def _extract_catchment_columns(data: pd.DataFrame) -> List[str]:
    return [col for col in data.columns if col.lower().startswith("catchment_")]

def _align_timeseries(
    station_data: pd.DataFrame,
    pixel_data: pd.DataFrame,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    if "date" in station_data.columns and "date" in pixel_data.columns:
        station = station_data.set_index("date")
        pixel = pixel_data.set_index("date")
        common_index = station.index.intersection(pixel.index)
        if common_index.empty:
            raise ValueError("No overlapping dates between station and pixel series")
        return station.loc[common_index], pixel.loc[common_index]
    if len(station_data) != len(pixel_data):
        raise ValueError("Station and pixel series must have the same length")
    return station_data.reset_index(drop=True), pixel_data.reset_index(drop=True)


def compute_from_dataframes(
    station_data: pd.DataFrame,
    pixel_data: pd.DataFrame,
) -> pd.DataFrame:
    station_columns = _extract_catchment_columns(station_data)
    pixel_columns = _extract_catchment_columns(pixel_data)

    if not station_columns:
        raise ValueError("Station CSV must contain 'catchment_' columns")
    if not pixel_columns:
        raise ValueError("Pixel CSV must contain 'catchment_' columns")

    station_aligned, pixel_aligned = _align_timeseries(station_data, pixel_data)

    results = []
    for pixel_col in pixel_columns:
        h_pixel = pixel_aligned[pixel_col].to_numpy(dtype=float)
        for station_col in station_columns:
            h_station = station_aligned[station_col].to_numpy(dtype=float)
            params = _compute_parameters(h_pixel, h_station)
            params.update({
                "pixel_id": pixel_col,
                "station_id": station_col,
            })
            results.append(params)

    columns_order = [
        "pixel_id",
        "station_id",
        "lambda_1t",
        "lambda_2t",
        "lambda_1",
        "lambda_2",
        "lambda_12",
        "alpha_1t",
        "alpha_2t",
        "alpha_1",
        "alpha_2",
        "alpha_1_12",
        "alpha_2_12",
        "r_alpha_12",
        "rho_1",
        "rho_2",
        "rho_3",
    ]

    return pd.DataFrame(results, columns=columns_order)

def compute_from_csvs(station_csv_path: str, pixel_csv_path: str) -> pd.DataFrame:
    station_data = pd.read_csv(station_csv_path)
    pixel_data = pd.read_csv(pixel_csv_path)
    return compute_from_dataframes(station_data, pixel_data)


def _apply_precipitation_threshold(
    data: pd.DataFrame,
    threshold: float | None,
) -> pd.DataFrame:
    if threshold is None:
        return data
    catchment_columns: List[str] = [
        col for col in data.columns if col.lower().startswith("catchment_")
    ]
    if not catchment_columns:
        return data
    thresholded = data.copy()
    thresholded[catchment_columns] = thresholded[catchment_columns].mask(
        thresholded[catchment_columns] < threshold,
        0.0,
    )
    return thresholded


def _format_threshold_label(threshold: float) -> str:
    return str(threshold).replace(".", "p")

def _resolve_csv_path(csv_dir: Path, csv_file: str | None = None) -> Path:
    """Restituisce il Path del CSV; se csv_file è None sceglie il .csv più recente nella cartella."""
    if csv_file:
        p = csv_dir / csv_file
        if not p.exists():
            raise FileNotFoundError(f"Non trovo il file: {p}")
        return p
    # Altrimenti cerca il più recente
    candidates = sorted(csv_dir.glob("*.csv"), key=lambda p: p.stat().st_mtime, reverse=True)
    if not candidates:
        raise FileNotFoundError(f"Nessun CSV trovato in {csv_dir}")
    return candidates[0]

def run_model(
    station_csv_path: str | Path | None = None,
    pixel_csv_path: str | Path | None = None,
    *,
    csv_dir: Path | None = None,
    station_csv_file: str | None = None,
    pixel_csv_file: str | None = None,
    output_dir: Path | None = None,
    precipitation_thresholds: List[float] | None = None,
) -> Path | List[Path] | None:
    if station_csv_path is None:
        resolved_station_csv = _resolve_csv_path(
            csv_dir or CSV_DIR,
            station_csv_file or STATION_CSV_FILE,
        )
    else:
        resolved_station_csv = Path(station_csv_path)
        if not resolved_station_csv.exists():
            raise FileNotFoundError(f"Non trovo il file: {resolved_station_csv}")

    if pixel_csv_path is None:
        resolved_pixel_csv = _resolve_csv_path(
            csv_dir or CSV_DIR,
            pixel_csv_file or PIXEL_CSV_FILE,
        )
    else:
        resolved_pixel_csv = Path(pixel_csv_path)
        if not resolved_pixel_csv.exists():
            raise FileNotFoundError(f"Non trovo il file: {resolved_pixel_csv}")

    print(f"Uso CSV stazioni: {resolved_station_csv}")
    print(f"Uso CSV pixel: {resolved_pixel_csv}")
    station_data = pd.read_csv(resolved_station_csv)
    pixel_data = pd.read_csv(resolved_pixel_csv)
    thresholds = precipitation_thresholds or [None]
    output_files: List[Path] = []
    multiple_thresholds = len(thresholds) > 1

    
    target_output_dir = Path(output_dir) if output_dir else OUTPUT_DIR
    target_output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    for threshold in thresholds:
        thresholded_station = _apply_precipitation_threshold(station_data, threshold)
        thresholded_pixel = _apply_precipitation_threshold(pixel_data, threshold)
        results = compute_from_dataframes(thresholded_station, thresholded_pixel)
        if results.empty:
            print("No station/pixel combinations found.")
            continue
        results.insert(
            0,
            "precipitation_threshold",
            float("nan") if threshold is None else threshold,
        )
        if threshold is None and not multiple_thresholds:
            output_file = target_output_dir / f"model_output_{timestamp}.csv"
        else:
            label = "none" if threshold is None else _format_threshold_label(threshold)
            output_file = target_output_dir / f"model_output_threshold_{label}_{timestamp}.csv"
        print(results.to_string(index=False))
        results.to_csv(output_file, index=False)
        print(f"Tabella salvata in: {output_file}")
        output_files.append(output_file)

    if not output_files:
        return None
    if len(output_files) == 1:
        return output_files[0]
    return output_files


def main() -> None:
    run_model()


if __name__ == "__main__":
    main()
