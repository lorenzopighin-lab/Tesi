# -*- coding: utf-8 -*-
"""
Created on Mon Oct  6 12:28:45 2025

@author: loren
"""

import os
import math
import csv
import array 
import matplotlib.colors as colors
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar
import numpy as np
import rasterio
import seaborn as sns
from pathlib import Path
from pysheds.grid import Grid
from rasterio.transform import rowcol
from Krig_4 import compute_catchment_precipitation_series


# --- Configurazione generale ---

dem_path  = "C:/Users/loren/Desktop/Tesi_magi/codes/data/DE12030.tif"
POUR_POINT = array.array('f', [8.710165, 52.197884	])
SNAP_ACCUMULATION_THRESHOLD = 100000
BRANCH_ACCUMULATION_THRESHOLD = 8000
MIN_ACCUMULATION_KM2 = 10


# --- Parametri dimensionali ---
# Il DEM è espresso in coordinate geografiche ma sappiamo che le celle
# rappresentano quadrati da 30 m di lato.  Per le operazioni che richiedono
# distanze o superfici in metri utilizziamo quindi questo fattore di
# conversione esplicito.
PIXEL_SIZE_METERS = 30.0
PIXEL_AREA_M2 = PIXEL_SIZE_METERS ** 2

# --- Parametri selezione pixel ---
# "equidistant": distribuisce i pixel intermedi in modo equidistante lungo il ramo
# "spacing": posiziona i pixel intermedi ogni INTERMEDIATE_SPACING_METERS lungo il ramo
# Sui rami più corti di MIN_BRANCH_LENGTH_FOR_INTERMEDIATE_METERS non vengono
# selezionati pixel intermedi.
PIXEL_PLACEMENT_MODE = "equidistant"
MAX_INTERMEDIATE_PIXELS = 2
INTERMEDIATE_SPACING_METERS = 600.0
MIN_BRANCH_LENGTH_FOR_INTERMEDIATE_METERS = 5000
MAIN_SEED_EXCLUSION_RADIUS_METERS = 5000.0

# --- Esportazione tabella pixel selezionati ---
PIXEL_TABLE_OUTPUT = Path("selected_pixels_table.csv")

# --- Configurazione piogge medie per catchment ---
PRECIP_CSV_DIR = Path("C:/Users/loren/Desktop/Tesi_magi/codes/data/DEA12030")
STATION_META_PATH = Path("C:/Users/loren/Desktop/Tesi_magi/codes/data/gauge_coord.csv")
PRECIP_DATE_START = "2010-01-01"
PRECIP_DATE_END = "2020-12-31"
PRECIP_BUFFER_METERS = 10000.0
PRECIP_MIN_STATIONS = 4
PRECIP_MAX_STATIONS = 30
CATCHMENT_SERIES_OUTPUT = Path("C:/Users/loren/Desktop/Tesi_magi/codes/kriging_out/catchment_precipitation_table.csv")

# --- Opzioni Kriging ---
RUN_KRIGING = True  # Imposta a False per saltare il calcolo delle precipitazioni
PROMPT_KRIGING_CATCHMENTS = True  # Chiedi da input gli ID dei catchment da interpolare
# Esempio: ["catchment_001", "catchment_010"] oppure stringa "catchment_001,catchment_010"
KRIGING_CATCHMENT_IDS = None

def _format_scalebar_label(length_meters: float) -> str:
    if length_meters >= 1000:
        km_value = length_meters / 1000.0
        if math.isclose(km_value, round(km_value), rel_tol=1e-9):
            return f"{int(round(km_value))} km"
        return f"{km_value:.1f} km"
    if math.isclose(length_meters, round(length_meters), rel_tol=1e-9):
        return f"{int(round(length_meters))} m"
    return f"{length_meters:.0f} m"


def add_scale_bar(
    ax,
    transform,
    *,
    preferred_lengths_meters=None,
    location="lower right",
    color="black",
):
    """Add a simple scale bar to ``ax`` based on the raster transform."""
    if transform is None:
        return
    try:
        pixel_width_units = abs(float(transform.a))
    except (AttributeError, TypeError, ValueError):
        pixel_width_units = None
    if not pixel_width_units:
        return
    meters_per_unit = PIXEL_SIZE_METERS / pixel_width_units
    if not np.isfinite(meters_per_unit) or meters_per_unit <= 0:
        return

    xlim = ax.get_xlim()
    axis_width_units = abs(xlim[1] - xlim[0])
    axis_width_meters = axis_width_units * meters_per_unit
    if axis_width_meters <= 0:
        return

    if not preferred_lengths_meters:
        preferred_lengths_meters = [50, 100, 200, 500, 1000, 2000, 5000, 10000]

    selected_length = None
    for candidate in preferred_lengths_meters:
        if candidate <= axis_width_meters * 0.4:
            selected_length = candidate
    if selected_length is None:
        selected_length = axis_width_meters / 5
    if selected_length <= 0 or not np.isfinite(selected_length):
        return

    length_data_units = selected_length / meters_per_unit
    if not np.isfinite(length_data_units) or length_data_units <= 0:
        return

    fontprops = fm.FontProperties(size=10)
    size_vertical = max(length_data_units * 0.05, axis_width_units * 0.002)
    scalebar = AnchoredSizeBar(
        ax.transData,
        length_data_units,
        _format_scalebar_label(selected_length),
        loc=location,
        pad=0.4,
        borderpad=0.4,
        sep=4,
        color=color,
        frameon=True,
        size_vertical=size_vertical,
        fontproperties=fontprops,
    )
    ax.add_artist(scalebar)

def _load_station_points(meta_path: Path):
    if not meta_path:
        return None, None
    try:
        with meta_path.open(newline="", encoding="utf-8") as fp:
            reader = csv.DictReader(fp)
            if not reader.fieldnames or {"lon", "lat"} - set(reader.fieldnames):
                print(
                    "Impossibile tracciare le stazioni: il file di metadata non contiene colonne 'lon' e 'lat'."
                )
                return None, None
            lons = []
            lats = []
            for row in reader:
                try:
                    lon = float(row["lon"])
                    lat = float(row["lat"])
                except (TypeError, ValueError):
                    continue
                if math.isfinite(lon) and math.isfinite(lat):
                    lons.append(lon)
                    lats.append(lat)
    except FileNotFoundError:
        print(f"File metadata stazioni non trovato: {meta_path}")
        return None, None
    except OSError as exc:
        print(f"Impossibile leggere il file metadata delle stazioni '{meta_path}': {exc}")
        return None, None

    if not lons or not lats:
        print("Nessuna coordinata valida trovata nel file di metadata delle stazioni.")
        return None, None
    return np.asarray(lons, dtype="float32"), np.asarray(lats, dtype="float32")


station_lons, station_lats = _load_station_points(STATION_META_PATH)

with rasterio.open(dem_path) as src:
    dem = src.read(1, out_dtype='float32')
    profile = src.profile

# --- Lettura dei dati di input ---
grid = Grid.from_raster(os.path.join(dem_path), nodata=-9999, data_name="grid data")
dem = grid.read_raster(os.path.join(dem_path), nodata=-9999, data_name="dem")

flooded_dem = grid.fill_depressions(dem)
inflated_dem = grid.resolve_flats(flooded_dem, eps=1e-6) #eps è importante
fdir = grid.flowdir(inflated_dem)

# Calcola l'accumulo di flusso a valle di ogni cella.
acc = grid.accumulation(fdir)

# Aggancia il punto di chiusura sul pixel con accumulo sufficiente.
x_snap, y_snap = grid.snap_to_mask(
    acc > SNAP_ACCUMULATION_THRESHOLD, POUR_POINT,)


# --- Visualizzazione accumulo di flusso e punto di chiusura ---
fig, ax = plt.subplots(figsize=(8, 6))
fig.patch.set_alpha(0)
plt.grid('on', zorder=3)
im = ax.imshow(acc, extent=grid.extent, zorder=2,
               cmap='cubehelix',
               norm=colors.LogNorm(1, acc.max()),
               interpolation='bilinear')
ax.scatter([x_snap], [y_snap], s=80, facecolors='none', edgecolors='red',
           linewidth=1.8, zorder=4, label='Punto')

plt.colorbar(im, ax=ax, label='Upstream Cells')
plt.title('Flow Accumulation', size=14)
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.tight_layout()


# Delineate the catchment
catch = grid.catchment(x=x_snap, y=y_snap, fdir=fdir, xytype='coordinate')

n_pixels = int(np.count_nonzero(catch))   # equivalente a int(catch.sum())
print("Pixel nel catchment:", n_pixels)

#%%%plots
# DEM
inflated_dem_masked = np.ma.masked_invalid(inflated_dem)

fig, ax = plt.subplots(figsize=(8, 6))
dem_im = ax.imshow(
    inflated_dem_masked,
    extent=grid.extent,
    cmap='terrain',
    origin='upper',
)
ax.scatter(
    [x_snap],
    [y_snap],
    s=80,
    facecolors='none',
    edgecolors='red',
    linewidth=1.8,
    label='Sezione di chiusura',
)
if (
    station_lons is not None
    and station_lats is not None
    and getattr(station_lons, "size", 0)
    and getattr(station_lats, "size", 0)
):
    ax.scatter(
        station_lons,
        station_lats,
        s=45,
        marker='^',
        facecolors='#f9c74f',
        edgecolors='black',
        linewidth=0.6,
        zorder=5,
        label='stazioni di misura',
    )
ax.set_title('DSM', size=14)
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
add_scale_bar(ax, grid.affine, location='lower right')
plt.colorbar(dem_im, ax=ax, label='Elevation')
ax.legend(loc='upper right')
plt.tight_layout()

# Catchment outline over DEM
fig, ax = plt.subplots(figsize=(8, 6))
dem_im = ax.imshow(
    inflated_dem_masked,
    extent=grid.extent,
    cmap='terrain',
    origin='upper',
)

# coordinate arrays for contour plotting
x_coords = np.linspace(grid.extent[0], grid.extent[1], catch.shape[1])
y_coords = np.linspace(grid.extent[3], grid.extent[2], catch.shape[0])

catch_bool = catch.astype(bool)
ax.contour(
    x_coords,
    y_coords,
    catch_bool,
    levels=[0.5],
    colors='dodgerblue',
    linewidths=1.8,
)

# optional filled overlay of the catchment (transparent red)
catch_overlay = np.ma.masked_where(~catch_bool, catch_bool)
ax.imshow(
    catch_overlay,
    extent=grid.extent,
    origin='upper',
    cmap=colors.ListedColormap([(1.0, 0.0, 0.0, 0.35)]),
    zorder=4,
)
ax.scatter(
    [x_snap],
    [y_snap],
    s=80,
    facecolors='none',
    edgecolors='red',
    linewidth=1.8,
    label='Punto',
)
ax.set_title('Catchment Outline on DEM', size=14)
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
add_scale_bar(ax, grid.affine, location='lower right')
plt.colorbar(dem_im, ax=ax, label='Elevation')
plt.tight_layout()
plt.show()
#%%branches
# Limita la griglia al bacino e ricava la rete drenante principale.
grid.clip_to(catch)
catch_view = grid.view(catch).astype(bool)
branches = grid.extract_river_network(
    fdir, acc > BRANCH_ACCUMULATION_THRESHOLD
)
                                      
# coordinate del seed principale nella view clippata
main_seed_row, main_seed_col = map(int, rowcol(grid.affine, x_snap, y_snap))
main_seed_x, main_seed_y = rasterio.transform.xy(
    grid.affine, main_seed_row, main_seed_col, offset="center")

#%%%plot branches 

sns.set_palette('husl')
fig, ax = plt.subplots(figsize=(8.5,6.5))

plt.xlim(grid.bbox[0], grid.bbox[2])
plt.ylim(grid.bbox[1], grid.bbox[3])
ax.set_aspect('equal')
add_scale_bar(ax, grid.affine, location='lower left')

for branch in branches['features']:
    line = np.asarray(branch['geometry']['coordinates'])
    plt.plot(line[:, 0], line[:, 1])
    
_ = plt.title(
    f"Channel network (>{BRANCH_ACCUMULATION_THRESHOLD} accumulation)",
    size=14,
)
#%% Impostazioni distribuzione pixel lungo i rami
# I parametri sono definiti nella sezione di configurazione iniziale.
# Rasterizza la rete per identificare i pixel appartenenti a ciascun ramo.

fdir_view = grid.view(fdir)
transform_view = grid.affine       # affine della view corrente (dopo il clip)
shape_view = fdir_view.shape

shapes = (
    (feat["geometry"], idx + 1) for idx, feat in enumerate(branches["features"])
)
branches_raster = rasterio.features.rasterize(
    shapes=shapes,
    out_shape=shape_view,
    transform=transform_view,
    fill=0,
    all_touched=False,
    dtype="uint16",
)


# --- identificazione delle confluenze e dei pixel a monte ---
acc_view = grid.view(acc)              # acc calcolato prima: acc = grid.accumulation(fdir)
H, W = acc_view.shape

cell_area_m2 = PIXEL_AREA_M2
cell_size_x = PIXEL_SIZE_METERS
cell_size_y = PIXEL_SIZE_METERS
thr_cells = math.ceil((MIN_ACCUMULATION_KM2 * 1e6) / cell_area_m2)

# Seleziona i pixel con accumulo sufficiente per essere considerati candidati.
mask_acc = acc_view >= thr_cells

# Offsets per analizzare i vicini secondo lo schema D8.
neighbor_offsets = [
    (-1, -1), (-1, 0), (-1, 1),
    (0, -1),           (0, 1),
    (1, -1),  (1, 0),  (1, 1),
]

# Mapping tra offset e codici di direzione del flusso D8.
d8_from_offset = {
    (-1, -1): 32,
    (-1, 0): 64,
    (-1, 1): 128,
    (0, -1): 16,
    (0, 1): 1,
    (1, -1): 8,
    (1, 0): 4,
    (1, 1): 2,
}

# Mapping inverso dai codici D8 all'offset.
d8_to_offset = {
    1: (0, 1),
    2: (1, 1),
    4: (1, 0),
    8: (1, -1),
    16: (0, -1),
    32: (-1, -1),
    64: (-1, 0),
    128: (-1, 1),
}


selected_coords_set = set()
selected_coords_list = []
# Mappa branch_id -> lista di pixel selezionati (per analisi e debug).
branch_selections = {}

def _add_selected_coord(rc):
    """Aggiunge una cella alla lista dei punti selezionati se valida."""
    if rc is None:
        return False
    r, c = map(int, rc)
    if not (0 <= r < H and 0 <= c < W):
        return False
    if catch_view is not None and not catch_view[r, c]:
        return False
    if not mask_acc[r, c]:
        return False

    key = (r, c)
    try:
        exclusion_radius = float(MAIN_SEED_EXCLUSION_RADIUS_METERS)
    except (TypeError, ValueError):
        exclusion_radius = 0.0
    if exclusion_radius > 0 and np.isfinite(exclusion_radius):
        main_seed_rc = (int(main_seed_row), int(main_seed_col))
        if key != main_seed_rc:
            dr_m = (r - main_seed_rc[0]) * cell_size_y
            dc_m = (c - main_seed_rc[1]) * cell_size_x
            distance = math.hypot(dr_m, dc_m)
            if distance <= exclusion_radius:
                return False
            
    if key in selected_coords_set:
        return False

    selected_coords_set.add(key)
    selected_coords_list.append(key)
    return True

unique_branch_ids = np.unique(branches_raster)
unique_branch_ids = unique_branch_ids[unique_branch_ids > 0]

# Per ciascun ramo seleziona pixel significativi lungo la direzione del flusso.
for branch_id in unique_branch_ids:
    branch_mask = branches_raster == branch_id
    candidate_indices = np.argwhere(branch_mask)
    if candidate_indices.size == 0:
        continue
    
# Filtra i pixel del ramo che soddisfano le condizioni sul bacino e sull'accumulo.
    filtered_coords = []
    for r, c in candidate_indices:
        if catch_view is not None and not catch_view[r, c]:
            continue
        if not mask_acc[r, c]:
            continue
        filtered_coords.append((int(r), int(c)))

    if not filtered_coords:
        continue

    filtered_coords.sort(key=lambda rc: acc_view[rc])
    n_coords = len(filtered_coords)

    # Distanze cumulative lungo il ramo (ordinate da monte a valle)
    cumulative_distances = [0.0]
    for idx in range(1, n_coords):
        r0, c0 = filtered_coords[idx - 1]
        r1, c1 = filtered_coords[idx]
        dr = (r1 - r0) * cell_size_y
        dc = (c1 - c0) * cell_size_x
        step_distance = math.hypot(dr, dc)
        cumulative_distances.append(cumulative_distances[-1] + step_distance)
    
    branch_length = cumulative_distances[-1] if cumulative_distances else 0.0
    try:
        min_branch_length = float(MIN_BRANCH_LENGTH_FOR_INTERMEDIATE_METERS)
    except (TypeError, ValueError):
        min_branch_length = 0.0
    if not np.isfinite(min_branch_length):
        min_branch_length = 0.0
    min_branch_length = max(0.0, min_branch_length)
    allow_intermediate_selection = branch_length >= min_branch_length

    branch_selected = []
    used_indices = set()


# Seleziona sempre l'estremo a valle del ramo.
    if _add_selected_coord(filtered_coords[-1]):
        branch_selected.append(filtered_coords[-1])
        used_indices.add(n_coords - 1)

# Numero massimo di slot disponibili per eventuali punti intermedi.
    available_slots = max(0, n_coords - 2)

    if (
        n_coords > 2
        and available_slots > 0
        and allow_intermediate_selection
    ):
        mode = (PIXEL_PLACEMENT_MODE or "").strip().lower()
        # Target distances esprime le posizioni desiderate lungo il ramo.
        target_distances = []

        if mode == "spacing":
            try:
                spacing_m = float(INTERMEDIATE_SPACING_METERS)
            except (TypeError, ValueError):
                spacing_m = 0.0
            if spacing_m > 0 and cumulative_distances[-1] > 0:
                n_targets = int(cumulative_distances[-1] // spacing_m)
                max_intermediate = None
                if MAX_INTERMEDIATE_PIXELS is not None:
                    try:
                        max_intermediate = int(MAX_INTERMEDIATE_PIXELS)
                    except (TypeError, ValueError):
                        max_intermediate = None
                if max_intermediate is not None:
                    n_targets = min(n_targets, max_intermediate)
                n_targets = min(n_targets, available_slots)
                target_distances = [spacing_m * i for i in range(1, n_targets + 1)]
        else:
            max_intermediate = None
            if MAX_INTERMEDIATE_PIXELS is not None:
                try:
                    max_intermediate = int(MAX_INTERMEDIATE_PIXELS)
                except (TypeError, ValueError):
                    max_intermediate = None
            if max_intermediate is not None:
                n_intermediate = min(max_intermediate, available_slots)
            else:
                n_intermediate = max(1, math.ceil(n_coords / 30))
                n_intermediate = min(n_intermediate, available_slots)

            if n_intermediate > 0 and cumulative_distances[-1] > 0:
                target_distances = np.linspace(
                    0, cumulative_distances[-1], n_intermediate + 2
                )[1:-1]

        for target_distance in target_distances:
            available_indices = [
                i for i in range(1, n_coords - 1) if i not in used_indices
            ]
            if not available_indices:
                break

            closest_idx = min(
                available_indices,
                key=lambda i: abs(cumulative_distances[i] - target_distance),
            )

            coord = filtered_coords[closest_idx]
            if _add_selected_coord(coord):
                branch_selected.append(coord)
            used_indices.add(closest_idx)

    if branch_selected:
        branch_selected.sort(key=lambda rc: acc_view[rc])
        branch_selections[int(branch_id)] = branch_selected

total_selected = sum(len(v) for v in branch_selections.values())
print(f"Selezionati {total_selected} pixel su {len(branch_selections)} rami.")

selected_coords_list.sort(key=lambda rc: (-acc_view[rc], rc[0], rc[1])) 
# Ordina i pixel per importanza (accumulo decrescente e coordinate stabili).


# --- 4) Risultati ---
# selected_mask: booleano con i pixel scelti, distanziati lungo la rete

# Mask dei canali, utile per gli snap e per vincolare la ricerca dei massimi.
channel_mask = branches_raster.astype(bool)
# Lista di dizionari con le informazioni principali di ciascun pixel selezionato.
selected_points = []

def _build_selected_mask(points):
    """Costruisce una mask booleana partendo dalla lista di punti selezionati."""
    mask = np.zeros_like(branches_raster, dtype=bool)
    for pt in points:
        r, c = pt.get("snapped_index", (None, None))
        if r is None or c is None:
            continue
        if 0 <= r < H and 0 <= c < W:
            mask[r, c] = True
    return mask


def _local_max_index(r, c, acc_arr, mask=None, max_radius=5):
    """Trova l'indice (row, col) della cella con accumulo massimo vicina."""
    h, w = acc_arr.shape
    if mask is not None:
        mask = mask.astype(bool)
    r = int(r)
    c = int(c)
    best_rc = (r, c)
    if 0 <= r < h and 0 <= c < w:
        best_val = acc_arr[r, c]
    else:
        best_val = -np.inf
    for radius in range(max_radius + 1):
        r0 = max(0, r - radius)
        r1 = min(h, r + radius + 1)
        c0 = max(0, c - radius)
        c1 = min(w, c + radius + 1)
        window = acc_arr[r0:r1, c0:c1]
        if window.size == 0:
            continue
        if mask is not None:
            mask_window = mask[r0:r1, c0:c1]
            if not mask_window.any():
                continue
            masked_vals = np.where(mask_window, window, -np.inf)
            idx = np.argmax(masked_vals)
            if np.isneginf(masked_vals.flat[idx]):
                continue
        else:
            idx = np.argmax(window)
        wr, wc = np.unravel_index(idx, window.shape)
        candidate_val = window[wr, wc]
        if candidate_val > best_val:
            best_val = candidate_val
            best_rc = (r0 + wr, c0 + wc)
        if mask is not None and mask_window[wr, wc]:
            return best_rc
    return best_rc

# Costruisce il set di punti selezionati con coordinate e informazioni di snap.
for rr, cc in selected_coords_list:
    point = {
        "row": int(rr),
        "col": int(cc),
        "original_index": (int(rr), int(cc)),
    }
    x, y = rasterio.transform.xy(grid.affine, rr, cc, offset="center")
    point["initial_coord"] = (float(x), float(y))

    snapped_xy = None
    if channel_mask.any():
        try:
            snapped_xy = grid.snap_to_mask(channel_mask, (x, y))
        except Exception:
            snapped_xy = None
    if snapped_xy is not None:
        xsnap, ysnap = snapped_xy
        try:
            rsnap_float, csnap_float = rowcol(grid.affine, xsnap, ysnap)
            rsnap, csnap = int(rsnap_float), int(csnap_float)
        except Exception:
            rsnap, csnap = int(rr), int(cc)
    else:
        rsnap, csnap = int(rr), int(cc)
        xsnap, ysnap = x, y


    if not (0 <= rsnap < H and 0 <= csnap < W) or not channel_mask[rsnap, csnap]:
        rsnap, csnap = _local_max_index(rr, cc, acc_view, mask=channel_mask)
        xsnap, ysnap = rasterio.transform.xy(
            grid.affine, rsnap, csnap, offset="center"
        )

    point["snapped_index"] = (int(rsnap), int(csnap))
    point["snapped_coord"] = (float(xsnap), float(ysnap))
    selected_points.append(point)

# Rimuovi eventuali duplicati basati sulle coordinate "snappate" e
# verifica che tutti i pixel selezionati abbiano coordinate distinte.
unique_points = []
seen_snapped_indices = set()
duplicate_count = 0

for point in selected_points:
    snapped_key = point.get("snapped_index")
    if snapped_key in seen_snapped_indices:
        duplicate_count += 1
        continue
    seen_snapped_indices.add(snapped_key)
    unique_points.append(point)

if duplicate_count:
    print(f"Rimossi {duplicate_count} pixel duplicati basati sulle coordinate snappate.")

selected_points = unique_points

# Controllo finale: assicurati che tutte le coordinate siano differenti.
assert len(selected_points) == len(seen_snapped_indices), (
    "Sono presenti pixel duplicati nelle coordinate selezionate.")

# --- Tabella dei pixel selezionati ---
def _format_float_or_empty(value, precision=6):
    if value is None:
        return ""
    try:
        if not math.isfinite(value):
            return ""
    except TypeError:
        return ""
    return f"{value:.{precision}f}"


def _format_int_or_empty(value):
    if value is None:
        return ""
    try:
        return str(int(value))
    except (TypeError, ValueError):
        return ""


pixel_table_rows = []
main_seed_rc = (int(main_seed_row), int(main_seed_col))

for idx, point in enumerate(selected_points, start=1):
    rsnap, csnap = point.get("snapped_index", (None, None))
    xsnap, ysnap = point.get("snapped_coord", (None, None))
    
    distance_m = None
    if rsnap is not None and csnap is not None:
        try:
            dr_m = (int(rsnap) - main_seed_rc[0]) * PIXEL_SIZE_METERS
            dc_m = (int(csnap) - main_seed_rc[1]) * PIXEL_SIZE_METERS
            distance_m = math.hypot(dr_m, dc_m)
        except (TypeError, ValueError):
            distance_m = None
            
    pixel_table_rows.append(
        {
            "id": idx,
            "row": rsnap,
            "col": csnap,
            "x": xsnap,
            "y": ysnap,
            "distance_m": distance_m,
        }
    )

if pixel_table_rows:
    header = ("ID", "Row", "Col", "X", "Y", "Distance_m")
    col_widths = [max(len(h), 5) for h in header]
    
    def _row_values(row):
        return (
            _format_int_or_empty(row["id"]),
            _format_int_or_empty(row["row"]),
            _format_int_or_empty(row["col"]),
            _format_float_or_empty(row["x"]),
            _format_float_or_empty(row["y"]),
            _format_float_or_empty(row.get("distance_m")),
        )

    for row in pixel_table_rows:
        values = _row_values(row)
        for idx_col, value in enumerate(values):
            col_widths[idx_col] = max(col_widths[idx_col], len(str(value)))

    def _print_row(values):
        formatted = [str(val).rjust(col_widths[i]) for i, val in enumerate(values)]
        print(" ".join(formatted))

    print("\nTabella pixel selezionati (coordinate snappate):")
    _print_row(header)
    print(" ".join("-" * width for width in col_widths))
    for row in pixel_table_rows:
        _print_row(_row_values(row))

    if PIXEL_TABLE_OUTPUT:
        try:
            with PIXEL_TABLE_OUTPUT.open("w", newline="", encoding="utf-8") as fp:
                writer = csv.writer(fp)
                writer.writerow(["pixel_id", "row", "col", "x", "y", "distance_m"])
                for row in pixel_table_rows:
                    writer.writerow(
                        [
                            row["id"],
                            row["row"],
                            row["col"],
                            row["x"],
                            row["y"],
                            row.get("distance_m"),
                        ]
                    )
            print(
                f"Tabella pixel salvata in {PIXEL_TABLE_OUTPUT.resolve()}"
            )
        except OSError as exc:
            print(
                f"Impossibile salvare la tabella pixel su {PIXEL_TABLE_OUTPUT}: {exc}"
            )
else:
    print("Nessun pixel selezionato: nessuna tabella da esportare.")

#%% Area contribuente dei pixel estratti (catchments)

xmin, ymin, xmax, ymax = grid.bbox

catchments = []   # lista di maschere boolean (una per punto)
areas = []        # area m² (o unità del tuo CRS) di ogni catchment
labels = np.zeros_like(fdir_view, dtype=np.int32)  # raster etichettato (facoltativo)
expected_areas = []
catchment_points = []
failed_points = []
catchment_ids = []

main_mask = grid.view(catch).astype(bool)   # maschera del bacino principale nella view clippata
catchments    = [main_mask] + catchments
catchment_ids = ["catchment_main"] + catchment_ids

os.makedirs("catchments_tif", exist_ok=True)

for point in selected_points:
    rsnap, csnap = point["snapped_index"]
    x_snap, y_snap = point["snapped_coord"]

    if not (0 <= rsnap < H and 0 <= csnap < W):
        failed_points.append({"point": point, "reason": "indice fuori dai limiti"})
        continue

    expected_area = acc_view[rsnap, csnap] * cell_area_m2
    if expected_area <= 0:
        failed_points.append({"point": point, "reason": "accumulation nulla"})
        continue

    def _compute_catchment(row, col):
        """Estrae l'area contribuente a partire da una cella della rete."""
        row = int(row)
        col = int(col)
        if not (0 <= row < H and 0 <= col < W):
            return None
        if catch_view is not None and not catch_view[row, col]:
            return None

        mask_local = np.zeros_like(fdir_view, dtype=bool)
        queue = [(row, col)]
        mask_local[row, col] = True
        head = 0

        while head < len(queue):
            cr, cc = queue[head]
            head += 1

            for dr in (-1, 0, 1):
                for dc in (-1, 0, 1):
                    if dr == 0 and dc == 0:
                        continue

                    nr, nc = cr + dr, cc + dc
                    if not (0 <= nr < H and 0 <= nc < W):
                        continue
                    if mask_local[nr, nc]:
                        continue
                    if catch_view is not None and not catch_view[nr, nc]:
                        continue

                    delta_row = cr - nr
                    delta_col = cc - nc
                    flow_code = d8_from_offset.get((delta_row, delta_col))
                    if flow_code is None:
                        continue

                    if fdir_view[nr, nc] == 0 or fdir_view[nr, nc] != flow_code:
                        continue

                    mask_local[nr, nc] = True
                    queue.append((nr, nc))

        if not mask_local.any():
            return None

        return mask_local

    mask = _compute_catchment(rsnap, csnap)

    # prova un nuovo snap basato sul massimo di accumulo locale se necessario
    if mask is None:
        alt_r, alt_c = _local_max_index(
            rsnap, csnap, acc_view, mask=channel_mask, max_radius=10)
        
        if (alt_r, alt_c) != (rsnap, csnap):
            rsnap, csnap = int(alt_r), int(alt_c)
            x_snap, y_snap = rasterio.transform.xy(
                grid.affine, rsnap, csnap, offset='center')
            
            expected_area = acc_view[rsnap, csnap] * cell_area_m2
            if expected_area > 0:
                mask = _compute_catchment(rsnap, csnap)

    if mask is None:
        x_orig, y_orig = point.get("initial_coord", (None, None))
        r_orig, c_orig = point["row"], point["col"]
        if (
            x_orig is not None
            and y_orig is not None
            and 0 <= r_orig < H
            and 0 <= c_orig < W
        ):
            expected_area_orig = acc_view[r_orig, c_orig] * cell_area_m2
            if expected_area_orig > 0:
                candidate_mask = _compute_catchment(r_orig, c_orig)
                if candidate_mask is not None:
                    mask = candidate_mask
                    rsnap, csnap = int(r_orig), int(c_orig)
                    x_snap, y_snap = float(x_orig), float(y_orig)
                    expected_area = expected_area_orig

    if mask is None:
        point["catchment_found"] = False
        failed_points.append({"point": point, "reason": "catchment non trovato"})
        continue
    
    point["catchment_found"] = True
    point["snapped_index"] = (int(rsnap), int(csnap))
    point["snapped_coord"] = (float(x_snap), float(y_snap))

    actual_area = mask.sum() * cell_area_m2
    deviation = (
        abs(actual_area - expected_area) / expected_area if expected_area else np.inf
    )
    if deviation > 0.2:
        print(
            f"Avviso: deviazione area {deviation*100:.1f}% per il seed in {x_snap:.2f}, {y_snap:.2f}"
        )

    label_id = len(catchment_ids)
    catchment_id = f"catchment_{label_id:03d}"
        
    catchments.append(mask)
    catchment_ids.append(catchment_id)
    areas.append(actual_area)
    expected_areas.append(expected_area)

    point["expected_area"] = float(expected_area)
    point["catchment_area"] = float(actual_area)
    point["deviation"] = float(deviation)
    catchment_points.append(point.copy())

    labels[mask & (labels == 0)] = label_id

selected_mask = _build_selected_mask(catchment_points)
pixels_selected = selected_mask.astype(np.uint8)

#%%%plot pixel sulla rete
sns.set_palette('husl')
fig, ax = plt.subplots(figsize=(8.5, 6.5))

plt.xlim(grid.bbox[0], grid.bbox[2])
plt.ylim(grid.bbox[1], grid.bbox[3])
ax.set_aspect('equal')

for branch in branches['features']:
    line = np.asarray(branch['geometry']['coordinates'])
    plt.plot(line[:, 0], line[:, 1])

sc = ax.scatter(
                    [pt["snapped_coord"][0] for pt in catchment_points],
                    [pt["snapped_coord"][1] for pt in catchment_points],
                    s=18, c='red',
                    edgecolors='k', linewidths=0.3,
                    zorder=5, label='Pixel selezionati')
_ = plt.title(
    f" Selected pixels on channel network (>{BRANCH_ACCUMULATION_THRESHOLD} accumulation)",
    size=14,
)

#%%%controllo pixels
count_ones = np.sum(branches_raster > 0)
selected_count = pixels_selected.sum()
print("Pixel canali", count_ones)
print("Numero confluences:", selected_count)

check = pixels_selected.astype(bool) & (branches_raster > 0)
check_ones = np.sum(check)
print("confluences sulla rete", check_ones)

if check_ones == selected_count:
    print("Pixel Trovati")
else:
    print("Discrepanze pixel rete")

if failed_points:
    print(f"Catchment non estratti: {len(failed_points)}")
    for item in failed_points:
        coord = item["point"].get("initial_coord", (np.nan, np.nan))
        print(f" - seed {coord} -> {item['reason']}")

xs = np.asarray([pt["snapped_coord"][0] for pt in catchment_points])
ys = np.asarray([pt["snapped_coord"][1] for pt in catchment_points])

print(f"Catchment estratti: {len(catchments) - 1}")
if expected_areas:
    areas_arr = np.asarray(areas)
    expected_arr = np.asarray(expected_areas)
    deviation_pct = np.where(expected_arr > 0,
                             np.abs(areas_arr - expected_arr) / expected_arr * 100,
                             np.nan)
    print(f"Deviazione media area rispetto ad accumulation: {np.nanmean(deviation_pct):.2f}%")
#%%% Plot Aree contribuenti

def plot_catchment_i(catchment_id,
                     catchments,        # lista di mask boolean (come creato prima)
                     xs, ys,            # coordinate dei seed (solo sottobacini)
                     catch,             # mask booleana del bacino principale (stessa view)
                     transform_view,    # grid.affine della view clippata
                     dem_view=None,     # opzionale: DEM nella view (stessa shape)
                     main_seed=None,    # opzionale: (x0, y0) seed del bacino principale
                     catchment_ids=None # opzionale: lista ID catchment per il titolo
                     ):
    """Visualizza il catchment richiesto sovrapposto al bacino principale.

    ``catchment_id`` può essere:

    * l'ID testuale del catchment (es. ``"catchment_001"``);
    * un indice intero della lista ``catchment_ids`` (es. ``1``);
    * una stringa contenente un intero (es. ``"1"``).
    """
    
    if not catchments:
        raise ValueError("Nessun catchment disponibile per il plotting")
    if not catchment_ids:
        raise ValueError("È necessario fornire gli ID dei catchment per il plotting")

    index = None

    if isinstance(catchment_id, int):
        index = catchment_id
    else:
        cid_str = str(catchment_id)
        if cid_str.isdigit():
            index = int(cid_str)
        else:
            try:
                index = catchment_ids.index(cid_str)
            except ValueError as exc:
                raise KeyError(f"Catchment ID '{catchment_id}' non trovato") from exc

    if index is None or not (0 <= index < len(catchment_ids)):
        raise IndexError(
            f"Indice catchment {catchment_id!r} fuori dall'intervallo disponibile"
        )

    mask_i = catchments[index]          # boolean array (H, W)
    h, w = mask_i.shape
    xmin, ymin, xmax, ymax = rasterio.transform.array_bounds(h, w, 
                                                             transform_view)

    fig, ax = plt.subplots(figsize=(7, 7))

    # 1) base DEM (opzionale)
    if dem_view is not None and dem_view.shape == mask_i.shape:
        ax.imshow(dem_view, extent=(xmin, xmax, ymin, ymax), origin="upper", 
                  cmap="gray")

    # 2) bacino principale in grigio trasparente
    ax.imshow(np.where(catch, 1, np.nan), extent=(xmin, xmax, ymin, ymax),
              origin="upper", alpha=0.25)
    
    # 4) sottobacino i-esimo più marcato
    ax.imshow(np.where(mask_i, 1, np.nan), extent=(xmin, xmax, ymin, ymax),
              origin="upper")
    
    # 3) rete di drenaggio
    for branch in branches['features']:
            line = np.asarray(branch['geometry']['coordinates'])
            plt.plot(line[:, 0], line[:, 1], alpha=0.5)
 

    # ) punti seed
    # seed del sottobacino i-esimo
    if main_seed is not None:
        ax.scatter(
            [main_seed[0]],
            [main_seed[1]],
            s=40,
            marker='^',
            edgecolor='k',
            linewidth=0.8,
            label="sezione principale",
        )
    
    catchment_label = catchment_ids[index]
    # punti seed dei sottobacini
    if xs is not None and ys is not None and len(xs) and len(ys):
        ax.scatter(
            xs,
            ys,
            s=20,
            c='red',
            edgecolor='k',
            linewidths=0.3,
            label='sezioni estratte',
        )

    # evidenzia il seed del sottobacino corrente
    highlighted_seed = None
    if index == 0:
        highlighted_seed = main_seed
    else:
        seed_index = index - 1
        if (
            xs is not None
            and ys is not None
            and 0 <= seed_index < len(xs)
        ):
            highlighted_seed = (xs[seed_index], ys[seed_index])

    if highlighted_seed is not None:
        ax.scatter(
            [highlighted_seed[0]],
            [highlighted_seed[1]],
            s=45,
            marker='o',
            facecolor='yellow',
            edgecolor='k',
            linewidth=0.6,
            label=f'sezione {catchment_label}',
        )

    ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)
    ax.set_xlabel("x"); ax.set_ylabel("y")
    ax.set_title(f"Area contribuente {catchment_label} su bacino principale")
    add_scale_bar(ax, transform_view, location='lower right')
    ax.legend(loc="best")
    plt.show()
    
    
catchment_selection = "catchment_155"  # può essere indice (es. 1) o ID (es. "catchment_001")
catchment_id_to_plot = catchment_selection if catchment_ids else None

if catchment_id_to_plot is not None:
    plot_catchment_i(
        catchment_id_to_plot,
        catchments=catchments,
        xs=xs,
        ys=ys,
        catch=grid.view(catch),
        transform_view=grid.affine,
        main_seed=(main_seed_x, main_seed_y),
        catchment_ids=catchment_ids,
    )
else:
    print("Nessun catchment valido da plottare.")

#%% Serie di precipitazione media per catchment
if not RUN_KRIGING:
    print("Kriging disabilitato; eseguita solo l'estrazione della rete.")
elif not catchments:
    print("Nessun catchment disponibile per il calcolo delle precipitazioni medie.")
else:
    crs_obj = profile.get("crs") if isinstance(profile, dict) else None
    dtm_crs = None
    if crs_obj is not None:
        dtm_crs = crs_obj.to_string() if hasattr(crs_obj, "to_string") else str(crs_obj)

    def _normalize_requested_ids(raw_ids):
        if raw_ids is None:
            return []
        if isinstance(raw_ids, (list, tuple, set)):
            items = [str(item) for item in raw_ids]
        else:
            items = [part for part in str(raw_ids).replace(";", ",").split(",")]
        normalized = []
        for item in items:
    
            clean = item.strip()
            if not clean:
                continue
            normalized.append(clean)
        return normalized

    requested_ids = _normalize_requested_ids(KRIGING_CATCHMENT_IDS)

    if not requested_ids and PROMPT_KRIGING_CATCHMENTS:
        try:
            user_input = input(
                "Inserisci gli ID dei catchment per il kriging (separati da virgola) "
                "oppure premi invio per tutti:"
            )
        except EOFError:
            user_input = ""
        user_input = user_input.strip()
        if user_input and user_input.lower() not in {"tutti", "all"}:
            requested_ids = _normalize_requested_ids(user_input)
        else:
            requested_ids = []

    catchment_map = dict(zip(catchment_ids, catchments))
    selected_ids = list(catchment_ids)
    selected_masks = list(catchments)

    if requested_ids:
        missing = [cid for cid in requested_ids if cid not in catchment_map]
        if missing:
            print(
                "Catchment non presenti tra quelli estratti: "
                + ", ".join(missing)
            )
        selected_ids = [cid for cid in requested_ids if cid in catchment_map]
    else:
        selected_ids = list(catchment_ids)
        if selected_ids:
            print(
                "Nessun ID specificato: verranno elaborati tutti i catchment disponibili."
            )
    
    selected_masks = [catchment_map[cid] for cid in selected_ids]

    if not selected_ids:
        print(
            "Nessun catchment selezionato per il kriging; eseguita solo l'estrazione della rete."
        )
    else:
        print(
            "Avvio calcolo serie di precipitazione media per catchment tramite kriging "
            f"({len(selected_ids)} catchment)."
        )
        try:
            precip_table = compute_catchment_precipitation_series(
                catchment_masks=selected_masks,
                transform=grid.affine,
                catchment_ids=selected_ids,
                csv_dir=PRECIP_CSV_DIR,
                station_meta=STATION_META_PATH,
                dtm_crs=dtm_crs,
                start_date=PRECIP_DATE_START,
                end_date=PRECIP_DATE_END,
                buffer_distance=PRECIP_BUFFER_METERS,
                min_stations=PRECIP_MIN_STATIONS,
                max_stations=PRECIP_MAX_STATIONS,
            )
            if not precip_table.empty:
                precip_table.to_csv(CATCHMENT_SERIES_OUTPUT, index=False)
                print(
                    "Tabella precipitazioni media catchment salvata in "
                    f"{CATCHMENT_SERIES_OUTPUT.resolve()}"
                )
            else:
                print(
                    "Nessuna serie di precipitazione calcolata: verificare dati di input o catchments."
                )
        except Exception as exc:
            print(f"Errore durante il calcolo delle serie di precipitazione: {exc}")
